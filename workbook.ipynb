{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008905708000384038\n",
      "0.00827308299994911\n",
      "0.008282875001896173\n",
      "Unique Venues in execution data: 6\n",
      "Unique TradeTimes in execution data: 3846\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import timeit\n",
    "\n",
    "# Read in data\n",
    "executions = pq.read_table('data/executions.parquet')\n",
    "market_data = pq.read_table('data/marketdata.parquet')\n",
    "refdata = pq.read_table('data/refdata.parquet')\n",
    "\n",
    "# Convert to pandas\n",
    "df_ex = executions.to_pandas()\n",
    "df_md = market_data.to_pandas()\n",
    "df_rf = refdata.to_pandas()\n",
    "\n",
    "\n",
    "def get_unique_column_values(df, column_name):\n",
    "    return len(df[column_name].unique())\n",
    "\n",
    "def get_unique_column_values_2(df, column_name):\n",
    "    return df[column_name].nunique()\n",
    "\n",
    "\n",
    "# Measure performance of each method\n",
    "print(timeit.timeit('get_unique_column_values(df_ex, \"Venue\")', globals=globals(), number=100))   # winner 0.0078\n",
    "print(timeit.timeit('df_ex.Venue.nunique()', globals=globals(), number=100))                      # 0.00819\n",
    "print(timeit.timeit('get_unique_column_values_2(df_ex, \"Venue\")', globals=globals(), number=100)) # 0.00853\n",
    "\n",
    "# Get unique count for Venue and TradeTimes\n",
    "print(f\"Unique Venues in execution data: {get_unique_column_values(df_ex, 'Venue')}\")\n",
    "print(f\"Unique TradeTimes in execution data: {get_unique_column_values(df_ex, 'TradeTime')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3558741250017192\n",
      "0.2392136250018666\n",
      "0.589178209000238\n",
      "0.2922007079978357\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning - performance checks\n",
    "\n",
    "# identify which column holds the CONTINUOUS_TRADING value\n",
    "df_ex.head()\n",
    "\n",
    "# Four methods to filter the dataframe on a column value or list of values\n",
    "\n",
    "def filter_df_on_column_value(df, column_name, column_value):\n",
    "    return df[df[column_name] == column_value]\n",
    "\n",
    "def filter_df_on_column_value2(df, column_name, column_value):\n",
    "    return df[df[column_name].values == column_value]\n",
    "\n",
    "def filter_df_with_query(df, column_name, column_value):\n",
    "    return df.query(f\"{column_name} == '{column_value}'\")\n",
    "\n",
    "def filter_df_by_values(dataframe, column_name, values):\n",
    "    \"\"\"\n",
    "    Filter a Pandas DataFrame by values in a specific column.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe (pd.DataFrame): The DataFrame to be filtered.\n",
    "    - column_name (str): The name of the column to filter on.\n",
    "    - values (list): A list of values to filter by.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The filtered DataFrame.\n",
    "    \"\"\"\n",
    "    return dataframe[dataframe[column_name].isin(values)]\n",
    "\n",
    "# Measure performance of each method\n",
    "\n",
    "print(timeit.timeit('filter_df_on_column_value(df_ex, \"Phase\", \"CONTINUOUS_TRADING\")', globals=globals(), number=1000)) # 0.368282958999770\n",
    "print(timeit.timeit('filter_df_on_column_value2(df_ex, \"Phase\", \"CONTINUOUS_TRADING\")', globals=globals(), number=1000)) # 0.24843849999888334\n",
    "print(timeit.timeit('filter_df_with_query(df_ex, \"Phase\", \"CONTINUOUS_TRADING\")', globals=globals(), number=1000)) # 0.5727733750009065\n",
    "print(timeit.timeit('filter_df_by_values(df_ex, \"Phase\", [\"CONTINUOUS_TRADING\"])', globals=globals(), number=1000)) # 0.2840273330002674\n",
    "\n",
    "# As we will want to be able to filter future data frames on a list we will stick with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations of execution data\n",
    "\n",
    "df_ex = filter_df_by_values(df_ex, 'Phase', [\"CONTINUOUS_TRADING\"])\n",
    "\n",
    "# Add column [‘side’], if quantity is negative, side = 2, if quantity is positive side = 1.\n",
    "df_ex['side'] = df_ex['Quantity'].apply(lambda x: 2 if x < 0 else 1)\n",
    "\n",
    "# Complement the data with refdata.parquet ex_rf by adding column primary_ticket and primary_mic on \n",
    "df_ex = pd.merge(df_ex, df_rf[['ISIN', 'primary_mic', 'primary_ticker', 'id']], on='ISIN', how='left')\n",
    "\n",
    "# Add listing_id to facilitate joining on market data \n",
    "df_ex['listing_id'] = df_ex['id']\n",
    "df_ex.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "# Set datatype for TradeTime\n",
    "df_ex['TradeTime'] = pd.to_datetime(df_ex['TradeTime'])\n",
    "\n",
    "# Filter execution data on market data listing_ids\n",
    "listing_ids = df_md['listing_id'].unique()\n",
    "df_ex = filter_df_by_values(df_ex, \"listing_id\", listing_ids)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations of market data\n",
    "\n",
    "# Filter the market data on the column market_state == CONTINUOUS_TRADING\n",
    "df_md = filter_df_by_values(df_md, \"market_state\", [\"CONTINUOUS_TRADING\"])\n",
    "df_md['event_timestamp'] = pd.to_datetime(df_md['event_timestamp'])\n",
    "\n",
    "# only keep the columns time, listing_id, best_bid_price, best_ask_price in the df_md dataframe\n",
    "df_md = df_md[['event_timestamp', 'listing_id', 'best_bid_price', 'best_ask_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations\n",
    "\n",
    "# Get the bbo at the time of the trade, 1s before the trade and 1s after the trade\n",
    "fields_to_rename = ['best_bid_price', 'best_ask_price']\n",
    "\n",
    "# Join the dataframes on 'listing_id' and 'primary_mic'\n",
    "final_df_0 = pd.merge_asof(df_ex.sort_values('TradeTime'), df_md.sort_values('event_timestamp'), left_on='TradeTime', right_on='event_timestamp', by='listing_id')\n",
    "final_df_0 = final_df_0.rename(columns={field: field.replace(\"_price\", \"\") for field in fields_to_rename})\n",
    "final_df_0.to_csv('data/final_df_0.csv', index=False)\n",
    "\n",
    "df_ex['TradeTime_min_1'] = df_ex['TradeTime'] - pd.DateOffset(seconds=1)\n",
    "final_df_less_1 = pd.merge_asof(df_ex.sort_values('TradeTime_min_1'), df_md.sort_values('event_timestamp'), left_on='TradeTime_min_1', right_on='event_timestamp', by='listing_id')\n",
    "final_df_less_1 = final_df_less_1.rename(columns={field: field.replace(\"_price\", \"_min_1s\") for field in fields_to_rename})\n",
    "final_df_less_1.to_csv('data/final_df_less_1.csv', index=False)\n",
    "\n",
    "df_ex['TradeTime_plus_1'] = df_ex['TradeTime'] + pd.DateOffset(seconds=1)\n",
    "final_df_plus_1 = pd.merge_asof(df_ex.sort_values('TradeTime_plus_1'), df_md.sort_values('event_timestamp'), left_on='TradeTime_plus_1', right_on='event_timestamp', by='listing_id')\n",
    "final_df_plus_1 = final_df_plus_1.rename(columns={field: field.replace(\"_price\", \"_1s\") for field in fields_to_rename})\n",
    "final_df_plus_1.to_csv('data/final_df_plus_1.csv', index=False)\n",
    "\n",
    "# merge final_df_0, final_df_less_1, final_df_plus_1 on listing_id and time\n",
    "common_columns = ['listing_id', 'TradeTime', 'ISIN', 'Currency', 'Venue', 'Price', 'Trade_id', 'Phase', 'Quantity', 'side', 'primary_mic', 'primary_ticker'] \n",
    "final_df = pd.merge(final_df_0, final_df_less_1, on=common_columns, how='left')\n",
    "final_df = pd.merge(final_df, final_df_plus_1, on=common_columns, how='left')\n",
    "\n",
    "\n",
    "# drop these columns event_timestamp_x,TradeTime_min_1_x,event_timestamp_y,TradeTime_min_1_y,TradeTime_plus_1,event_timestamp\n",
    "final_df.drop(['event_timestamp_x', 'TradeTime_min_1_x', 'event_timestamp_y', 'TradeTime_min_1_y', 'TradeTime_plus_1', 'event_timestamp'], axis=1, inplace=True)\n",
    "final_df.to_csv('data/final_df.csv', index=False)\n",
    "\n",
    "# to be converted into a function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mid price and the spread\n",
    "\n",
    "# Find the Mid-Price at execution, 1s before the execution and 1s after the execution – respective column table names [‘mid_price’, ‘mid_price_min_1s’ ‘mid_price_1s’]\n",
    "final_df['mid_price'] = (final_df['best_bid'] + final_df['best_ask']) / 2\n",
    "final_df['mid_price_min_1s'] = (final_df['best_bid_min_1s'] + final_df['best_ask_min_1s']) / 2\n",
    "final_df['mid_price_1s'] = (final_df['best_bid_1s'] + final_df['best_ask_1s']) / 2\n",
    "\n",
    "\n",
    "# Calculate Slippage [‘slippage’] at execution price\n",
    "#  For SELL: (execution_price – best_bid) / (best_ask – best_bid)\n",
    "#  For BUY : (best_ask – execution_price) / (best_ask – best_bid)\n",
    "\n",
    "def calculate_slippage(row):\n",
    "    if row['side'] == 1:\n",
    "        return (row['Price'] - row['best_bid']) / (row['best_ask'] - row['best_bid'])\n",
    "    else:\n",
    "        return (row['best_ask'] - row['Price']) / (row['best_ask'] - row['best_bid'])\n",
    "    \n",
    "final_df['slippage'] = final_df.apply(calculate_slippage, axis=1)\n",
    "final_df.to_csv('data/final_df.csv', index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
